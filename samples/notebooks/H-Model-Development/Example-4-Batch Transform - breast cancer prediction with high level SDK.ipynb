{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "42b5e80b-ad1d-4335-a1f7-10a91127e3dc"
    }
   },
   "source": [
    "# Amazon SageMaker Batch Transform: Associate prediction results with their corresponding input records\n",
    "_**Use SageMaker's XGBoost to train a binary classification model and for a list of tumors in batch file, predict if each is malignant**_\n",
    "\n",
    "_**It also shows how to use the input output joining / filter feature in Batch transform in details**_\n",
    "\n",
    "---\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "2. [Setup](#Setup)\n",
    "3. [Data Preparation](#Data-Preparation)\n",
    " 1. [Key Observations](#Key-Observations)\n",
    "4. [Training Job and Model Creation](#Training-Job-and-Model-Creation)\n",
    "5. [Batch Transform](#Batch-Transform)\n",
    "  1. [Create a transform job with the default configurations](#Create-a-transform-job-with-the-default-configurations)\n",
    "  2. [Join the input and the prediction results](#Join-the-input-and-the-prediction-results)\n",
    "  3. [Update the output filter to keep only ID and prediction results](#Update-the-output-filter-to-keep-only-ID-and-prediction-results)\n",
    "\n",
    "\n",
    "## Background\n",
    "This purpose of this notebook is to train a model using SageMaker's XGBoost and UCI's breast cancer diagnostic data set to illustrate at how to run batch inferences and how to use the Batch Transform I/O join feature. UCI's breast cancer diagnostic data set is available at https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29. The data set is also available on Kaggle at https://www.kaggle.com/uciml/breast-cancer-wisconsin-data. The purpose here is to use this data set to build a predictve model of whether a breast mass image indicates benign or malignant tumor. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "* The SageMaker role arn used to give training and batch transform access to your data. The snippet below will use the same role used by your SageMaker notebook instance. Otherwise, specify the full ARN of a role with the SageMakerFullAccess policy attached.\n",
    "* The S3 bucket that you want to use for training and storing model objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "isConfigCell": true,
    "nbpresent": {
     "id": "6427e831-8f89-45c0-b150-0b134397d79a"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base-image-address': '198245574422.dkr.ecr.us-west-2.amazonaws.com/datamaker-dev-env-jupyter-user', 'bootstrap-s3-prefix': 'teams/lake-creator/bootstrap/', 'ecs-cluster-name': 'datamaker-dev-env-lake-creator-cluster', 'ecs-container-runner-arn': 'arn:aws:states:us-west-2:198245574422:stateMachine:datamaker-dev-env-lake-creator-ecs-container-runner', 'ecs-task-definition-arn': 'arn:aws:ecs:us-west-2:198245574422:task-definition/datamaker-dev-env-lake-creator-task-definition:18', 'efs-id': 'fs-46242543', 'eks-container-runner-arn': 'arn:aws:states:us-west-2:198245574422:stateMachine:datamaker-dev-env-lake-creator-eks-container-runner', 'eks-nodegroup-role-arn': 'arn:aws:iam::198245574422:role/datamaker-dev-env-lake-creator-role', 'final-image-address': '198245574422.dkr.ecr.us-west-2.amazonaws.com/datamaker-dev-env-lake-creator', 'grant-sudo': False, 'image': None, 'instance-type': 'm5.4xlarge', 'jupyter-url': 'aeeff621e69504f32915abeb04d55740-523956185.us-west-2.elb.amazonaws.com', 'jupyterhub-inbound-ranges': ['0.0.0.0/0'], 'local-storage-size': 128, 'name': 'lake-creator', 'nodes-num-desired': 2, 'nodes-num-max': 3, 'nodes-num-min': 1, 'plugins': [{'name': 'code_commit', 'parameters': {}, 'path': '../plugins/code_commit/'}, {'name': 'hello_world', 'parameters': {'foo': 'boo', 'xoo': 123}, 'path': '../plugins/hello_world/'}], 'policies': ['datamaker-dev-env-lake-bucket-fullaccess'], 'scratch-bucket': 'datamaker-dev-env-lake-creator-scratch-198245574422-165ae2', 'scratch-retention-days': 30, 'ssm-parameter-name': '/datamaker/dev-env/teams/lake-creator/manifest', 'stack-name': 'datamaker-dev-env-lake-creator', 'region': 'us-west-2', 'env_name': 'dev-env', 'team_space': 'lake-creator'}\n",
      "arn:aws:iam::198245574422:role/datamaker-dev-env-lake-creator-role\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from datamaker_sdk.common import get_workspace, get_demo\n",
    "\n",
    "workspace = get_workspace()\n",
    "print(workspace)\n",
    "#role = sagemaker.get_execution_role()\n",
    "role = workspace['eks-nodegroup-role-arn']\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "bucket=sess.default_bucket()\n",
    "prefix = 'sagemaker/breast-cancer-prediction-xgboost' # place to upload training files within the bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "142777ae-c072-448e-b941-72bc75735d01"
    }
   },
   "source": [
    "---\n",
    "## Data preparation\n",
    "\n",
    "Data Source: https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\n",
    "        https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "\n",
    "Let's download the data and save it in the local folder with the name data.csv and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "f8976dad-6897-4c7e-8c95-ae2f53070ef5"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>8911834</td>\n",
       "      <td>B</td>\n",
       "      <td>13.850</td>\n",
       "      <td>15.18</td>\n",
       "      <td>88.99</td>\n",
       "      <td>587.4</td>\n",
       "      <td>0.09516</td>\n",
       "      <td>0.07688</td>\n",
       "      <td>0.04479</td>\n",
       "      <td>0.03711</td>\n",
       "      <td>...</td>\n",
       "      <td>14.980</td>\n",
       "      <td>21.74</td>\n",
       "      <td>98.37</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.17240</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.09993</td>\n",
       "      <td>0.2955</td>\n",
       "      <td>0.06912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>919537</td>\n",
       "      <td>B</td>\n",
       "      <td>10.960</td>\n",
       "      <td>17.62</td>\n",
       "      <td>70.79</td>\n",
       "      <td>365.6</td>\n",
       "      <td>0.09687</td>\n",
       "      <td>0.09752</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.02788</td>\n",
       "      <td>...</td>\n",
       "      <td>11.620</td>\n",
       "      <td>26.51</td>\n",
       "      <td>76.43</td>\n",
       "      <td>407.5</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.25100</td>\n",
       "      <td>0.2123</td>\n",
       "      <td>0.09861</td>\n",
       "      <td>0.2289</td>\n",
       "      <td>0.08278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>892189</td>\n",
       "      <td>M</td>\n",
       "      <td>11.760</td>\n",
       "      <td>18.14</td>\n",
       "      <td>75.00</td>\n",
       "      <td>431.1</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>0.05914</td>\n",
       "      <td>0.02685</td>\n",
       "      <td>0.03515</td>\n",
       "      <td>...</td>\n",
       "      <td>13.360</td>\n",
       "      <td>23.39</td>\n",
       "      <td>85.10</td>\n",
       "      <td>553.6</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>0.07974</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>921092</td>\n",
       "      <td>B</td>\n",
       "      <td>7.729</td>\n",
       "      <td>25.49</td>\n",
       "      <td>47.98</td>\n",
       "      <td>178.8</td>\n",
       "      <td>0.08098</td>\n",
       "      <td>0.04878</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.077</td>\n",
       "      <td>30.92</td>\n",
       "      <td>57.17</td>\n",
       "      <td>248.0</td>\n",
       "      <td>0.1256</td>\n",
       "      <td>0.08340</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.3058</td>\n",
       "      <td>0.09938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>91544001</td>\n",
       "      <td>B</td>\n",
       "      <td>12.220</td>\n",
       "      <td>20.04</td>\n",
       "      <td>79.47</td>\n",
       "      <td>453.1</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.11520</td>\n",
       "      <td>0.08175</td>\n",
       "      <td>0.02166</td>\n",
       "      <td>...</td>\n",
       "      <td>13.160</td>\n",
       "      <td>24.17</td>\n",
       "      <td>85.13</td>\n",
       "      <td>515.3</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.23150</td>\n",
       "      <td>0.3535</td>\n",
       "      <td>0.08088</td>\n",
       "      <td>0.2709</td>\n",
       "      <td>0.08839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>86973701</td>\n",
       "      <td>B</td>\n",
       "      <td>14.950</td>\n",
       "      <td>18.77</td>\n",
       "      <td>97.84</td>\n",
       "      <td>689.5</td>\n",
       "      <td>0.08138</td>\n",
       "      <td>0.11670</td>\n",
       "      <td>0.09050</td>\n",
       "      <td>0.03562</td>\n",
       "      <td>...</td>\n",
       "      <td>16.250</td>\n",
       "      <td>25.47</td>\n",
       "      <td>107.10</td>\n",
       "      <td>809.7</td>\n",
       "      <td>0.0997</td>\n",
       "      <td>0.25210</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.08405</td>\n",
       "      <td>0.2852</td>\n",
       "      <td>0.09218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>8910499</td>\n",
       "      <td>B</td>\n",
       "      <td>13.590</td>\n",
       "      <td>21.84</td>\n",
       "      <td>87.16</td>\n",
       "      <td>561.0</td>\n",
       "      <td>0.07956</td>\n",
       "      <td>0.08259</td>\n",
       "      <td>0.04072</td>\n",
       "      <td>0.02142</td>\n",
       "      <td>...</td>\n",
       "      <td>14.800</td>\n",
       "      <td>30.04</td>\n",
       "      <td>97.66</td>\n",
       "      <td>661.5</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.06189</td>\n",
       "      <td>0.2446</td>\n",
       "      <td>0.07024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>864033</td>\n",
       "      <td>B</td>\n",
       "      <td>9.777</td>\n",
       "      <td>16.99</td>\n",
       "      <td>62.50</td>\n",
       "      <td>290.2</td>\n",
       "      <td>0.10370</td>\n",
       "      <td>0.08404</td>\n",
       "      <td>0.04334</td>\n",
       "      <td>0.01778</td>\n",
       "      <td>...</td>\n",
       "      <td>11.050</td>\n",
       "      <td>21.47</td>\n",
       "      <td>71.68</td>\n",
       "      <td>367.0</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.17650</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.05334</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>0.08468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "279   8911834         B       13.850         15.18           88.99      587.4   \n",
       "534    919537         B       10.960         17.62           70.79      365.6   \n",
       "297    892189         M       11.760         18.14           75.00      431.1   \n",
       "538    921092         B        7.729         25.49           47.98      178.8   \n",
       "506  91544001         B       12.220         20.04           79.47      453.1   \n",
       "147  86973701         B       14.950         18.77           97.84      689.5   \n",
       "267   8910499         B       13.590         21.84           87.16      561.0   \n",
       "110    864033         B        9.777         16.99           62.50      290.2   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "279          0.09516           0.07688         0.04479              0.03711   \n",
       "534          0.09687           0.09752         0.05263              0.02788   \n",
       "297          0.09968           0.05914         0.02685              0.03515   \n",
       "538          0.08098           0.04878         0.00000              0.00000   \n",
       "506          0.10960           0.11520         0.08175              0.02166   \n",
       "147          0.08138           0.11670         0.09050              0.03562   \n",
       "267          0.07956           0.08259         0.04072              0.02142   \n",
       "110          0.10370           0.08404         0.04334              0.01778   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "279  ...        14.980          21.74            98.37       670.0   \n",
       "534  ...        11.620          26.51            76.43       407.5   \n",
       "297  ...        13.360          23.39            85.10       553.6   \n",
       "538  ...         9.077          30.92            57.17       248.0   \n",
       "506  ...        13.160          24.17            85.13       515.3   \n",
       "147  ...        16.250          25.47           107.10       809.7   \n",
       "267  ...        14.800          30.04            97.66       661.5   \n",
       "110  ...        11.050          21.47            71.68       367.0   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "279            0.1185            0.17240           0.1456   \n",
       "534            0.1428            0.25100           0.2123   \n",
       "297            0.1137            0.07974           0.0612   \n",
       "538            0.1256            0.08340           0.0000   \n",
       "506            0.1402            0.23150           0.3535   \n",
       "147            0.0997            0.25210           0.2500   \n",
       "267            0.1005            0.17300           0.1453   \n",
       "110            0.1467            0.17650           0.1300   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "279               0.09993          0.2955                  0.06912  \n",
       "534               0.09861          0.2289                  0.08278  \n",
       "297               0.07160          0.1978                  0.06915  \n",
       "538               0.00000          0.3058                  0.09938  \n",
       "506               0.08088          0.2709                  0.08839  \n",
       "147               0.08405          0.2852                  0.09218  \n",
       "267               0.06189          0.2446                  0.07024  \n",
       "110               0.05334          0.2533                  0.08468  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', header = None)\n",
    "data = pd.read_csv('./wdbc.data', header = None)\n",
    "\n",
    "\n",
    "# specify columns extracted from wbdc.names\n",
    "data.columns = [\"id\",\"diagnosis\",\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\n",
    "                \"compactness_mean\",\"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\n",
    "                \"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\n",
    "                \"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\n",
    "                \"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\"concavity_worst\",\n",
    "                \"concave points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\"] \n",
    "\n",
    "# save the data\n",
    "data.to_csv(\"data.csv\", sep=',', index=False)\n",
    "\n",
    "data.sample(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key observations:\n",
    "* The data has 569 observations and 32 columns.\n",
    "* The first field is the 'id' attribute that we will want to drop before batch inference and add to the final inference output next to the probability of malignancy.\n",
    "* Second field, 'diagnosis', is an indicator of the actual diagnosis ('M' = Malignant; 'B' = Benign).\n",
    "* There are 30 other numeric features that we will use for training and inferencing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace the M/B diagnosis with a 1/0 boolean value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>874158</td>\n",
       "      <td>0</td>\n",
       "      <td>10.080</td>\n",
       "      <td>15.11</td>\n",
       "      <td>63.76</td>\n",
       "      <td>317.5</td>\n",
       "      <td>0.09267</td>\n",
       "      <td>0.04695</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>...</td>\n",
       "      <td>11.87</td>\n",
       "      <td>21.18</td>\n",
       "      <td>75.39</td>\n",
       "      <td>437.0</td>\n",
       "      <td>0.1521</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.00692</td>\n",
       "      <td>0.01042</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.07697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>89864002</td>\n",
       "      <td>0</td>\n",
       "      <td>11.710</td>\n",
       "      <td>15.45</td>\n",
       "      <td>75.03</td>\n",
       "      <td>420.3</td>\n",
       "      <td>0.11500</td>\n",
       "      <td>0.07281</td>\n",
       "      <td>0.040060</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>...</td>\n",
       "      <td>13.06</td>\n",
       "      <td>18.16</td>\n",
       "      <td>84.16</td>\n",
       "      <td>516.4</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>0.10870</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.07806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>859283</td>\n",
       "      <td>1</td>\n",
       "      <td>14.780</td>\n",
       "      <td>23.94</td>\n",
       "      <td>97.40</td>\n",
       "      <td>668.3</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.126700</td>\n",
       "      <td>0.090290</td>\n",
       "      <td>...</td>\n",
       "      <td>17.31</td>\n",
       "      <td>33.39</td>\n",
       "      <td>114.60</td>\n",
       "      <td>925.1</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.3416</td>\n",
       "      <td>0.30240</td>\n",
       "      <td>0.16140</td>\n",
       "      <td>0.3321</td>\n",
       "      <td>0.08911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>886776</td>\n",
       "      <td>1</td>\n",
       "      <td>15.320</td>\n",
       "      <td>17.27</td>\n",
       "      <td>103.20</td>\n",
       "      <td>713.3</td>\n",
       "      <td>0.13350</td>\n",
       "      <td>0.22840</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>...</td>\n",
       "      <td>17.73</td>\n",
       "      <td>22.66</td>\n",
       "      <td>119.80</td>\n",
       "      <td>928.8</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>0.44290</td>\n",
       "      <td>0.22290</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>0.11910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>915186</td>\n",
       "      <td>0</td>\n",
       "      <td>9.268</td>\n",
       "      <td>12.87</td>\n",
       "      <td>61.49</td>\n",
       "      <td>248.7</td>\n",
       "      <td>0.16340</td>\n",
       "      <td>0.22390</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.052520</td>\n",
       "      <td>...</td>\n",
       "      <td>10.28</td>\n",
       "      <td>16.38</td>\n",
       "      <td>69.05</td>\n",
       "      <td>300.2</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.3441</td>\n",
       "      <td>0.20990</td>\n",
       "      <td>0.10250</td>\n",
       "      <td>0.3038</td>\n",
       "      <td>0.12520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>915664</td>\n",
       "      <td>0</td>\n",
       "      <td>14.810</td>\n",
       "      <td>14.70</td>\n",
       "      <td>94.66</td>\n",
       "      <td>680.7</td>\n",
       "      <td>0.08472</td>\n",
       "      <td>0.05016</td>\n",
       "      <td>0.034160</td>\n",
       "      <td>0.025410</td>\n",
       "      <td>...</td>\n",
       "      <td>15.61</td>\n",
       "      <td>17.58</td>\n",
       "      <td>101.70</td>\n",
       "      <td>760.2</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.1011</td>\n",
       "      <td>0.11010</td>\n",
       "      <td>0.07955</td>\n",
       "      <td>0.2334</td>\n",
       "      <td>0.06142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>86208</td>\n",
       "      <td>1</td>\n",
       "      <td>20.260</td>\n",
       "      <td>23.03</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>0.09078</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.086830</td>\n",
       "      <td>...</td>\n",
       "      <td>24.22</td>\n",
       "      <td>31.59</td>\n",
       "      <td>156.10</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.3539</td>\n",
       "      <td>0.40980</td>\n",
       "      <td>0.15730</td>\n",
       "      <td>0.3689</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>879523</td>\n",
       "      <td>1</td>\n",
       "      <td>15.120</td>\n",
       "      <td>16.68</td>\n",
       "      <td>98.78</td>\n",
       "      <td>716.6</td>\n",
       "      <td>0.08876</td>\n",
       "      <td>0.09588</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>...</td>\n",
       "      <td>17.77</td>\n",
       "      <td>20.24</td>\n",
       "      <td>117.70</td>\n",
       "      <td>989.5</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.33270</td>\n",
       "      <td>0.12520</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.09740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "185    874158          0       10.080         15.11           63.76   \n",
       "344  89864002          0       11.710         15.45           75.03   \n",
       "65     859283          1       14.780         23.94           97.40   \n",
       "257    886776          1       15.320         17.27          103.20   \n",
       "504    915186          0        9.268         12.87           61.49   \n",
       "511    915664          0       14.810         14.70           94.66   \n",
       "95      86208          1       20.260         23.03          132.40   \n",
       "205    879523          1       15.120         16.68           98.78   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "185      317.5          0.09267           0.04695        0.001597   \n",
       "344      420.3          0.11500           0.07281        0.040060   \n",
       "65       668.3          0.11720           0.14790        0.126700   \n",
       "257      713.3          0.13350           0.22840        0.244800   \n",
       "504      248.7          0.16340           0.22390        0.097300   \n",
       "511      680.7          0.08472           0.05016        0.034160   \n",
       "95      1264.0          0.09078           0.13130        0.146500   \n",
       "205      716.6          0.08876           0.09588        0.075500   \n",
       "\n",
       "     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "185             0.002404  ...         11.87          21.18            75.39   \n",
       "344             0.032500  ...         13.06          18.16            84.16   \n",
       "65              0.090290  ...         17.31          33.39           114.60   \n",
       "257             0.124200  ...         17.73          22.66           119.80   \n",
       "504             0.052520  ...         10.28          16.38            69.05   \n",
       "511             0.025410  ...         15.61          17.58           101.70   \n",
       "95              0.086830  ...         24.22          31.59           156.10   \n",
       "205             0.040790  ...         17.77          20.24           117.70   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "185       437.0            0.1521             0.1019          0.00692   \n",
       "344       516.4            0.1460             0.1115          0.10870   \n",
       "65        925.1            0.1648             0.3416          0.30240   \n",
       "257       928.8            0.1765             0.4503          0.44290   \n",
       "504       300.2            0.1902             0.3441          0.20990   \n",
       "511       760.2            0.1139             0.1011          0.11010   \n",
       "95       1750.0            0.1190             0.3539          0.40980   \n",
       "205       989.5            0.1491             0.3331          0.33270   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "185               0.01042          0.2933                  0.07697  \n",
       "344               0.07864          0.2765                  0.07806  \n",
       "65                0.16140          0.3321                  0.08911  \n",
       "257               0.22290          0.3258                  0.11910  \n",
       "504               0.10250          0.3038                  0.12520  \n",
       "511               0.07955          0.2334                  0.06142  \n",
       "95                0.15730          0.3689                  0.08368  \n",
       "205               0.12520          0.3415                  0.09740  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['diagnosis']=data['diagnosis'].apply(lambda x: ((x ==\"M\"))+0)\n",
    "data.sample(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data as follows: 80% for training, 10% for validation and let's set 10% aside for our batch inference job. In addition, let's drop the 'id' field on the training set and validation set as 'id' is not a training feature. For our batch set however, we keep the 'id' feature. We'll want to filter it out prior to running our inferences so that the input data features match the ones of training set and then ultimately, we'll want to join it with inference result. We are however dropping the diagnosis attribute for the batch set since this is what we'll try to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split in three sets, training, validation and batch inference\n",
    "rand_split = np.random.rand(len(data))\n",
    "train_list = rand_split < 0.8\n",
    "val_list = (rand_split >= 0.8) & (rand_split < 0.9)\n",
    "batch_list = rand_split >= 0.9\n",
    "\n",
    "data_train = data[train_list].drop(['id'],axis=1)\n",
    "data_val = data[val_list].drop(['id'],axis=1)\n",
    "data_batch = data[batch_list].drop(['diagnosis'],axis=1)\n",
    "data_batch_noID = data_batch.drop(['id'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ff9d10f9-b611-423b-80da-6dcdafd1c8b9"
    }
   },
   "source": [
    "Let's upload those data sets in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "cd8e3431-79d9-40b6-91d1-d67cd61894e7"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-198245574422/sagemaker/breast-cancer-prediction-xgboost/batch/batch_data_noID.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = 'train_data.csv'\n",
    "data_train.to_csv(train_file,index=False,header=False)\n",
    "sess.upload_data(train_file, key_prefix='{}/train'.format(prefix))\n",
    "\n",
    "validation_file = 'validation_data.csv'\n",
    "data_val.to_csv(validation_file,index=False,header=False)\n",
    "sess.upload_data(validation_file, key_prefix='{}/validation'.format(prefix))\n",
    "\n",
    "batch_file = 'batch_data.csv'\n",
    "data_batch.to_csv(batch_file,index=False,header=False)\n",
    "sess.upload_data(batch_file, key_prefix='{}/batch'.format(prefix))\n",
    "    \n",
    "batch_file_noID = 'batch_data_noID.csv'\n",
    "data_batch_noID.to_csv(batch_file_noID,index=False,header=False)\n",
    "sess.upload_data(batch_file_noID, key_prefix='{}/batch'.format(prefix))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "71cbcebd-a2a5-419e-8e50-b2bc0909f564"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Training job and model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bd113b8e-adc1-4091-a26f-a426149fe604"
    }
   },
   "source": [
    "The below cell uses the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to kick off the training job using both our training set and validation set. Not that the objective is set to 'binary:logistic' which trains a model to output a probability between 0 and 1 (here the probability of a tumor being malignant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "f3b125ad-a2d5-464c-8cfa-bd203034eee4"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='1.0-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '1.0-1').\n",
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-14 19:00:36 Starting - Starting the training job...\n",
      "2020-12-14 19:00:39 Starting - Launching requested ML instances......\n",
      "2020-12-14 19:01:50 Starting - Preparing the instances for training...\n",
      "2020-12-14 19:02:46 Downloading - Downloading input data...\n",
      "2020-12-14 19:03:18 Training - Training image download completed. Training in progress.\n",
      "2020-12-14 19:03:18 Uploading - Uploading generated training model\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:03:13:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:03:13:INFO] File size need to be processed in the node: 0.13mb. Available memory size in the node: 54796.09mb\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:03:13:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[19:03:13] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[19:03:13] 445x30 matrix with 13350 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:03:13:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[19:03:13] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[19:03:13] 68x30 matrix with 2040 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.058427#011validation-error:0.220588\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.05618#011validation-error:0.147059\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.035955#011validation-error:0.161765\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.051685#011validation-error:0.147059\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.042697#011validation-error:0.102941\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.024719#011validation-error:0.102941\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.022472#011validation-error:0.102941\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.022472#011validation-error:0.117647\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 6 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.020225#011validation-error:0.088235\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.017978#011validation-error:0.073529\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.01573#011validation-error:0.088235\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 4 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.01573#011validation-error:0.073529\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.01573#011validation-error:0.088235\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.01573#011validation-error:0.073529\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 2 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.017978#011validation-error:0.073529\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 2 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.017978#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 0 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.017978#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.011236#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.011236#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.01573#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 0 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 2 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\u001b[34m[19:03:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.013483#011validation-error:0.058824\u001b[0m\n",
      "\n",
      "2020-12-14 19:03:25 Completed - Training job completed\n",
      "Training seconds: 39\n",
      "Billable seconds: 39\n",
      "CPU times: user 343 ms, sys: 38.2 ms, total: 381 ms\n",
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "\n",
    "job_name = 'xgb-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "output_location = 's3://{}/{}/output/{}'.format(bucket, prefix, job_name)\n",
    "image = get_image_uri(boto3.Session().region_name, 'xgboost')\n",
    "\n",
    "sm_estimator = sagemaker.estimator.Estimator(image,\n",
    "                                             role,\n",
    "                                             train_instance_count=1,\n",
    "                                             train_instance_type='ml.m5.4xlarge',\n",
    "                                             train_volume_size=50,\n",
    "                                             input_mode='File',\n",
    "                                             output_path=output_location,\n",
    "                                             sagemaker_session=sess)\n",
    "\n",
    "sm_estimator.set_hyperparameters(objective=\"binary:logistic\",\n",
    "                                 max_depth=5,\n",
    "                                 eta=0.2,\n",
    "                                 gamma=4,\n",
    "                                 min_child_weight=6,\n",
    "                                 subsample=0.8,\n",
    "                                 silent=0,\n",
    "                                 num_round=100)\n",
    "\n",
    "train_data = sagemaker.session.s3_input('s3://{}/{}/train'.format(bucket, prefix), distribution='FullyReplicated', \n",
    "                                        content_type='text/csv', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input('s3://{}/{}/validation'.format(bucket, prefix), distribution='FullyReplicated', \n",
    "                                             content_type='text/csv', s3_data_type='S3Prefix')\n",
    "data_channels = {'train': train_data, 'validation': validation_data}\n",
    "\n",
    "\n",
    "# Start training by calling the fit method in the estimator\n",
    "sm_estimator.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "397fb60a-c48b-453f-88ea-4d832b70c919"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Batch Transform\n",
    "\n",
    "In SageMaker Batch Transform, we introduced 3 new attributes - __input_filter__, __join_source__ and __output_filter__. In the below cell, we use the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to kick-off several Batch Transform jobs using different configurations of these 3 new attributes. Please refer to [this page](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html) to learn more about how to use them.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a transform job with the default configurations\n",
    "Let's first skip these 3 new attributes and inspect the inference results. We'll use it as a baseline to compare to the results with data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[32m2020-12-14T19:09:03.343:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:09:03 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:09:03 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:09:03 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:09:03 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:09:03:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:09:03 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:09:03:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:09:03:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:09:03:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:09:03 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:09:03 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:09:03:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:09:03:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:09:03 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:09:03 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:09:03 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:09:03 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:09:03:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:09:03 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:09:03:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:09:03:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:09:03:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:09:03 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:09:03 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:09:03:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:09:03:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\n",
      "CPU times: user 511 ms, sys: 32.3 ms, total: 543 ms\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sm_transformer = sm_estimator.transformer(1, 'ml.m4.xlarge')\n",
    "\n",
    "# start a transform job\n",
    "input_location = 's3://{}/{}/batch/{}'.format(bucket, prefix, batch_file_noID) # use input data without ID column\n",
    "sm_transformer.transform(input_location, split_type='Line')\n",
    "sm_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the output of the Batch Transform job in S3. It should show the list probabilities of tumors being malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def get_csv_output_from_s3(s3uri, file_name):\n",
    "    parsed_url = urlparse(s3uri)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    prefix = parsed_url.path[1:]\n",
    "    s3 = boto3.resource('s3')\n",
    "    obj = s3.Object(bucket_name, '{}/{}'.format(prefix, file_name))\n",
    "    return obj.get()[\"Body\"].read().decode('utf-8')    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.593490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.983232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.990054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.965993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.068566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.844889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.011774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.225861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.593490\n",
       "1  0.983232\n",
       "2  0.990054\n",
       "3  0.965993\n",
       "4  0.068566\n",
       "5  0.844889\n",
       "6  0.011774\n",
       "7  0.225861"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_csv_output_from_s3(sm_transformer.output_path, '{}.out'.format(batch_file_noID))\n",
    "output_df = pd.read_csv(io.StringIO(output), sep=\",\", header=None)\n",
    "output_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Join the input and the prediction results \n",
    "Now, let's associate the prediction results with their corresponding input records. We can also use the __input_filter__ to exclude the ID column easily and there's no need to have a separate file in S3.\n",
    "\n",
    "* Set __input_filter__ to \"$[1:]\": indicates that we are excluding column 0 (the 'ID') before processing the inferences and keeping everything from column 1 to the last column (all the features or predictors)  \n",
    "  \n",
    "  \n",
    "* Set __join_source__ to \"Input\": indicates our desire to join the input data with the inference results  \n",
    "\n",
    "* Leave __output_filter__ to default ('$'), indicating that the joined input and inference results be will saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      ".\u001b[32m2020-12-14T19:14:35.167:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:14:35 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:14:35 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:14:35 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:14:35 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:14:35 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:14:35 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:14:35:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:14:35:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:14:35:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:14:35 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:14:35:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:14:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:14:35:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:14:35 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:14:35 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:14:35 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:14:35 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:14:35 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:14:35 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:14:35:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:14:35:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:14:35:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:14:35 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:14:35:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:14:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:14:35:INFO] Model loaded successfully for worker : 39\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# content_type / accept and split_type / assemble_with are required to use IO joining feature\n",
    "sm_transformer.assemble_with = 'Line'\n",
    "sm_transformer.accept = 'text/csv'\n",
    "\n",
    "# start a transform job\n",
    "input_location = 's3://{}/{}/batch/{}'.format(bucket, prefix, batch_file) # use input data with ID column cause InputFilter will filter it out\n",
    "sm_transformer.transform(input_location, split_type='Line', content_type='text/csv', input_filter='$[1:]', join_source='Input')\n",
    "sm_transformer.wait()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the output of the Batch Transform job in S3. It should show the list of tumors identified by their original feature columns and their corresponding probabilities of being malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>843786</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>0.593490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84610002</td>\n",
       "      <td>15.78</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>...</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.983232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>848406</td>\n",
       "      <td>14.68</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.05259</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0.990054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8511133</td>\n",
       "      <td>15.34</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.20770</td>\n",
       "      <td>0.09756</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>...</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.6305</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "      <td>0.965993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>855167</td>\n",
       "      <td>13.44</td>\n",
       "      <td>21.58</td>\n",
       "      <td>86.18</td>\n",
       "      <td>563.0</td>\n",
       "      <td>0.08162</td>\n",
       "      <td>0.06031</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>0.02031</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>...</td>\n",
       "      <td>30.25</td>\n",
       "      <td>102.50</td>\n",
       "      <td>787.9</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.11120</td>\n",
       "      <td>0.2994</td>\n",
       "      <td>0.07146</td>\n",
       "      <td>0.068566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>85638502</td>\n",
       "      <td>13.17</td>\n",
       "      <td>21.81</td>\n",
       "      <td>85.42</td>\n",
       "      <td>531.5</td>\n",
       "      <td>0.09714</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.08259</td>\n",
       "      <td>0.05252</td>\n",
       "      <td>0.1746</td>\n",
       "      <td>...</td>\n",
       "      <td>29.89</td>\n",
       "      <td>105.50</td>\n",
       "      <td>740.7</td>\n",
       "      <td>0.1503</td>\n",
       "      <td>0.3904</td>\n",
       "      <td>0.3728</td>\n",
       "      <td>0.16070</td>\n",
       "      <td>0.3693</td>\n",
       "      <td>0.09618</td>\n",
       "      <td>0.844889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>857155</td>\n",
       "      <td>12.05</td>\n",
       "      <td>14.63</td>\n",
       "      <td>78.04</td>\n",
       "      <td>449.3</td>\n",
       "      <td>0.10310</td>\n",
       "      <td>0.09092</td>\n",
       "      <td>0.06592</td>\n",
       "      <td>0.02749</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>...</td>\n",
       "      <td>20.70</td>\n",
       "      <td>89.88</td>\n",
       "      <td>582.6</td>\n",
       "      <td>0.1494</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.06548</td>\n",
       "      <td>0.2747</td>\n",
       "      <td>0.08301</td>\n",
       "      <td>0.011774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>857156</td>\n",
       "      <td>13.49</td>\n",
       "      <td>22.30</td>\n",
       "      <td>86.91</td>\n",
       "      <td>561.0</td>\n",
       "      <td>0.08752</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.04751</td>\n",
       "      <td>0.03384</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>31.82</td>\n",
       "      <td>99.00</td>\n",
       "      <td>698.8</td>\n",
       "      <td>0.1162</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.12820</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.06917</td>\n",
       "      <td>0.225861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2       3      4        5        6        7        8   \\\n",
       "0    843786  12.45  15.70   82.57  477.1  0.12780  0.17000  0.15780  0.08089   \n",
       "1  84610002  15.78  17.89  103.60  781.0  0.09710  0.12920  0.09954  0.06606   \n",
       "2    848406  14.68  20.13   94.74  684.5  0.09867  0.07200  0.07395  0.05259   \n",
       "3   8511133  15.34  14.26  102.50  704.4  0.10730  0.21350  0.20770  0.09756   \n",
       "4    855167  13.44  21.58   86.18  563.0  0.08162  0.06031  0.03110  0.02031   \n",
       "5  85638502  13.17  21.81   85.42  531.5  0.09714  0.10470  0.08259  0.05252   \n",
       "6    857155  12.05  14.63   78.04  449.3  0.10310  0.09092  0.06592  0.02749   \n",
       "7    857156  13.49  22.30   86.91  561.0  0.08752  0.07698  0.04751  0.03384   \n",
       "\n",
       "       9   ...     22      23      24      25      26      27       28  \\\n",
       "0  0.2087  ...  23.75  103.40   741.6  0.1791  0.5249  0.5355  0.17410   \n",
       "1  0.1842  ...  27.28  136.50  1299.0  0.1396  0.5609  0.3965  0.18100   \n",
       "2  0.1586  ...  30.88  123.40  1138.0  0.1464  0.1871  0.2914  0.16090   \n",
       "3  0.2521  ...  19.08  125.10   980.9  0.1390  0.5954  0.6305  0.23930   \n",
       "4  0.1784  ...  30.25  102.50   787.9  0.1094  0.2043  0.2085  0.11120   \n",
       "5  0.1746  ...  29.89  105.50   740.7  0.1503  0.3904  0.3728  0.16070   \n",
       "6  0.1675  ...  20.70   89.88   582.6  0.1494  0.2156  0.3050  0.06548   \n",
       "7  0.1809  ...  31.82   99.00   698.8  0.1162  0.1711  0.2282  0.12820   \n",
       "\n",
       "       29       30        31  \n",
       "0  0.3985  0.12440  0.593490  \n",
       "1  0.3792  0.10480  0.983232  \n",
       "2  0.3029  0.08216  0.990054  \n",
       "3  0.4667  0.09946  0.965993  \n",
       "4  0.2994  0.07146  0.068566  \n",
       "5  0.3693  0.09618  0.844889  \n",
       "6  0.2747  0.08301  0.011774  \n",
       "7  0.2871  0.06917  0.225861  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_csv_output_from_s3(sm_transformer.output_path, '{}.out'.format(batch_file))\n",
    "output_df = pd.read_csv(io.StringIO(output), sep=\",\", header=None)\n",
    "output_df.head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Update the output filter to keep only ID and prediction results\n",
    "Let's change __output_filter__ to \"$[0,-1]\", indicating that when presenting the output, we only want to keep column 0 (the 'ID') and the last column (the inference result i.e. the probability of a given tumor to be malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................\n",
      "\u001b[32m2020-12-14T19:20:11.448:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:20:11 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:20:11 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:20:11 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:20:11 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:20:11 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:20:11 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:20:11:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-12-14 19:20:11 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:20:11:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:20:11:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:20:11:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:20:11:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-12-14:19:20:11:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:20:11 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:20:11 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:20:11 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:20:11 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:20:11 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:20:11 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:20:11:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-12-14 19:20:11 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:20:11:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:20:11:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:20:11:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:20:11:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-12-14:19:20:11:INFO] Model loaded successfully for worker : 40\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# start another transform job\n",
    "sm_transformer.transform(input_location, split_type='Line', content_type='text/csv', input_filter='$[1:]', join_source='Input', output_filter='$[0,-1]')\n",
    "sm_transformer.wait()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's inspect the output of the Batch Transform job in S3 again. It should show 2 columns: the ID and their corresponding probabilities of being malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>843786</td>\n",
       "      <td>0.593490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84610002</td>\n",
       "      <td>0.983232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>848406</td>\n",
       "      <td>0.990054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8511133</td>\n",
       "      <td>0.965993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>855167</td>\n",
       "      <td>0.068566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>85638502</td>\n",
       "      <td>0.844889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>857155</td>\n",
       "      <td>0.011774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>857156</td>\n",
       "      <td>0.225861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0    843786  0.593490\n",
       "1  84610002  0.983232\n",
       "2    848406  0.990054\n",
       "3   8511133  0.965993\n",
       "4    855167  0.068566\n",
       "5  85638502  0.844889\n",
       "6    857155  0.011774\n",
       "7    857156  0.225861"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_csv_output_from_s3(sm_transformer.output_path, '{}.out'.format(batch_file))\n",
    "output_df = pd.read_csv(io.StringIO(output), sep=\",\", header=None)\n",
    "output_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, we can use newly introduced 3 attributes - __input_filter__, __join_source__, __output_filter__ to \n",
    "1. Filter / select useful features from the input dataset. e.g. exclude ID columns.\n",
    "2. Associate the prediction results with their corresponding input records.\n",
    "3. Filter the original or joined results before saving to S3. e.g. keep ID and probability columns only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the License). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the license file accompanying this file. This file is distributed on an AS IS BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
