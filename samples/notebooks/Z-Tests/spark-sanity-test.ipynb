{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Testing that Spark Is Working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "import sparkmagic.utils.configuration as conf\n",
    "conf.override(conf.livy_session_startup_timeout_seconds.__name__, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local \n",
    "cluster_name = os.environ['cluster_name'] \n",
    "reuse_cluster = eval(os.environ['reuse_cluster'] )\n",
    "start_cluster = eval(os.environ['start_cluster'] )\n",
    "terminate_cluster = eval(os.environ['terminate_cluster'] )\n",
    "\n",
    "(cluster_name,reuse_cluster,start_cluster, terminate_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%local\n",
    "import aws.utils.notebooks.spark.emr as sparkConnection\n",
    "\n",
    "(livy_url, cluster_id, started) = sparkConnection.connect_to_spark(cluster_name,\n",
    "                                                                 reuseCluster=reuse_cluster, \n",
    "                                                                 startCluster=start_cluster, \n",
    "                                                                 clusterArgs={\n",
    "                                                                        \"CoreInstanceCount\":5\n",
    "                                                                  })\n",
    "(livy_url, cluster_id, started) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%spark -s spark -c spark -l python -u $livy_url -t None ADD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark -s spark -c spark -l python -u $livy_url -t None ADD --skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# no parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql -s spark -o result\n",
    "\n",
    "select 1 as Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "\n",
    "val = result.at[0,'Test']\n",
    "assert val==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark delete -s spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "if terminate_cluster:\n",
    "    sparkConnection.stop_cluster(cluster_id)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}